---
header-includes:
  - \usepackage{setspace}
  - \doublespacing
---

# Distribution of Artificial Intelligence #

There are a large number of issues that are present in the world of Artificial
Intelligence, many of which have extensive moral and ethical considerations.
However, many of these issues are about how the artificial intelligence should
act, or be made, or what it should be used for. This paper will instead focus
on the ethical implications of the distribution of the artificial intelligence.

Most highly powerful artificial intelligence software is currently created by
corporations, that aim to use this software for their products. And because of
this most of the artificial intelligence programs are not released to the
public for use. However, there are many tools that provide frameworks that are
made publicly available such as [^TensorFlow] to name one. Even with such
frameworks, almost all of the highly advanced neural networks are kept private
within a company, and it is left on the communities to develop their own
networks, which are most likely not on par with those developed by the original
developers.

One major example of this is in relation to self-driving vehicles. Since this
is one of the major current focuses of artificial intelligence, there are a
large number of competing developers for creating the most suitable neural
network for the job. To name a few there are Tesla, Waymo, Uber, Drive.ai, and
the list continues. The point is of these major developers of self-driving
technology, none of their software is publicly available. For now, the fact
that all the software is private is considered acceptable, as most of the
algorithms are still being developed and so are not to an acceptable standard.

However, it must be considered, should the software be made public? With the
expansion of automobiles with self-driving, or some form of driving assistance,
most if not all new vehicles have some form of artificial intelligence
implemented in it. However, each manufacturer is keeping their software private
(to my knowledge). In practice, AI is intended to help humanity, and make life
easier and safer. Thus when there is a fatal accident caused by a self-driving
car [^Uber] it must be questioned whether the software between major
manufacturers should be distributed, and thus each developer is able to
collaboratively contribute to the software, in theory making it more robust and
develop faster.

With some rough math that is at the end of the paper, the safety of each
major self-driving software developer is compared. It can be concluded that
from the rough calculations, that there is a wide range of experience in the
different networks, and most of them are less experienced than that of human
driving. However, in just the range of safety that is present in the different
self-driving systems, there are extreme outliers. Uber's self-driving system,
is currently the least safe of the development systems, and Tesla's is
currently the safest.

With this variation between the different levels of safety for the different
artificial intelligence implementations, the major developers should morally
release their software. Taking the most recent fatal accident by
Uber's vehicle into consideration. Could it have been avoided if the vehicle
was running with Tesla's more experienced and safer AI, or if the two companies
had collaborated on the software could the death be avoided? These two
questions are impossible to know for certain. This is a critical question to be
considered. Because one developer's software is substantially safer than
another, it is ethically and morally acceptable to keep that software private,
when releasing it could potentially save peoples lives?

If major manufacturers were to collaborate on one artificial-intelligence, then
the development would move faster with more developers an more testing
environments and this could potentially lead to a safer system as a whole, and
save peoples lives.

# Calculations #

## Humans ##
$37,000 \frac{death}{year} \approx 101 \frac{death}{day}$ [^asirt]

$245.5x10^9 \frac{miles}{month} \approx 7.92x10^9 \frac{miles}{day}$[^fha]

$7.84x10^7 \frac{miles}{death}$

## Tesla ##
$\frac{2 deaths}{4 years} \approx 1.7x10^{-3} \frac{death}{day}$

$\frac{300,000,000 miles}{4 years} \approx 2.05x10^5 \frac{miles}{day}$[^electrek]

$1.5x10^8 \frac{miles}{death}$

## Uber ##
$\frac{2 deaths}{3 years} \approx 1.9x10^{-3} \frac{death}{day}$

$\frac{2,000,000 miles}{3 years} \approx 1.98x10^3 \frac{miles}{day}$[^forbes]

$1.4x10^6 \frac{miles}{death}$

[^TensorFlow]: [www.tensorflow.org](https://www.tensorflow.org)
[^Uber]: [www.theverge.com/2018/3/28/17174636/uber-self-driving-crash-fatal-arizona-update](https://www.theverge.com/2018/3/28/17174636/uber-self-driving-crash-fatal-arizona-update)
[^asirt]: [http://asirt.org/initiatives/informing-road-users/road-safety-facts/road-crash-statistics](http://asirt.org/initiatives/informing-road-users/road-safety-facts/road-crash-statistics)
[^fha]: [https://www.fhwa.dot.gov/policyinformation/travel_monitoring/18jantvt/](https://www.fhwa.dot.gov/policyinformation/travel_monitoring/18jantvt/)
[^electrek]:
  [https://electrek.co/2016/11/13/tesla-autopilot-billion-miles-data-self-driving-program/](https://electrek.co/2016/11/13/tesla-autopilot-billion-miles-data-self-driving-program/)
[^forbes]:
  (https://www.forbes.com/sites/bizcarson/2017/12/22/ubers-self-driving-cars-2-million-miles/#1a3b5507a4fe)[https://www.forbes.com/sites/bizcarson/2017/12/22/ubers-self-driving-cars-2-million-miles/#1a3b5507a4fe]
